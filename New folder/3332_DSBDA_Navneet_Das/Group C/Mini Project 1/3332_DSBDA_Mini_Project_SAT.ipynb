{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lvYOJEiPFzBu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-colab\n",
      "  Downloading google-colab-1.0.0.tar.gz (72 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-auth~=1.4.0\n",
      "  Downloading google_auth-1.4.2-py2.py3-none-any.whl (64 kB)\n",
      "Collecting ipykernel~=4.6.0\n",
      "  Downloading ipykernel-4.6.1-py3-none-any.whl (104 kB)\n",
      "Collecting ipython~=5.5.0\n",
      "  Downloading ipython-5.5.0-py3-none-any.whl (758 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\http\\client.py\", line 458, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\http\\client.py\", line 502, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 164, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 205, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 338, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 482, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 374, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 214, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 205, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 201, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 281, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 225, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 292, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 482, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 527, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 213, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 94, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\Vishwa\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Vishwa\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting notebook~=5.2.0\n",
      "  Downloading notebook-5.2.2-py2.py3-none-any.whl (8.0 MB)\n",
      "Collecting six~=1.12.0\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pandas~=0.24.0\n",
      "  Downloading pandas-0.24.2.tar.gz (11.8 MB)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ti34ZhZoHYtq"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# test data\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Fg-P77KrIZ9x",
    "outputId": "740f1b18-6e56-4881-f153-6f5b8b0b36e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Analytics\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Ht0ct0Z4I0ii",
    "outputId": "69ece279-726c-48bc-fb95-6de5e2f62c66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "17192  49155  thought factory: left-right polarisation! #tru...\n",
       "17193  49156  feeling like a mermaid ð #hairflip #neverre...\n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
       "17195  49158  happy, at work conference: right mindset leads...\n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzXZEQ8JJOZ8",
    "outputId": "951ebb05-bba9-486a-af02-1b1f1575d627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any missing values\n",
    "train.isnull().sum()\n",
    "#train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FIbiavgOJTr_"
   },
   "outputs": [],
   "source": [
    "# remove special characters using the regular expression library\n",
    "import re\n",
    "\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIxXvzNOJvjZ",
    "outputId": "1bc09589-0c8f-4565-8dd1-83f4f12d96bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000018A03FAF9D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tweet-preprocessor/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000018A03FAFBE0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tweet-preprocessor/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000018A03FAFD90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tweet-preprocessor/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000018A03FAFF40>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tweet-preprocessor/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000018A03FDC130>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tweet-preprocessor/\n",
      "ERROR: Could not find a version that satisfies the requirement tweet-preprocessor (from versions: none)\n",
      "ERROR: No matching distribution found for tweet-preprocessor\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Vishwa\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JZG2kNE2KCvY"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3ba35a02b05a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mtempArr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocessor'"
     ]
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpYPiI1nKHLV"
   },
   "outputs": [],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"tweet\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "gfZswcMeKK0_",
    "outputId": "baef9f34-f150-4fea-e3a5-71d09db67ae8"
   },
   "outputs": [],
   "source": [
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lNK4nsGaKNTi",
    "outputId": "9b8fdbed-4608-4138-e5e1-666f3a9d77eb"
   },
   "outputs": [],
   "source": [
    "# clean the test data and append the cleaned tweets to the test data\n",
    "test_tweet = clean_tweets(test[\"tweet\"])\n",
    "test_tweet = pd.DataFrame(test_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "test[\"clean_tweet\"] = test_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aX2uXqiKWg5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# extract the labels from the train data\n",
    "y = train.label.values\n",
    "\n",
    "# use 70% for the training and 30% for the test\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.clean_tweet.values, y, stratify=y,random_state=1,test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnNZ0ecFNuLO",
    "outputId": "71b2ad38-88dc-4862-adaa-1adcfb36341e"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "uRrxdtk5KZtz",
    "outputId": "b0161602-d3d4-4178-ff40-feb4225a82c7"
   },
   "outputs": [],
   "source": [
    "#converting tweets into matrix using countvactrioser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = [\"My name is Navneet Das and I am a computer engineering student at Army Institute of Technology Pune\"]\n",
    "\n",
    "# initializing the countvectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and make the document into a matrix\n",
    "document_term_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# check the result\n",
    "pd.DataFrame(document_term_matrix.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6LMkvMCLbay"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(x_train) + list(x_test))\n",
    "\n",
    "# transform documents to document-term matrix\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PArOfDIELlY5"
   },
   "outputs": [],
   "source": [
    "# Model building Using SVM algorithm\n",
    "# classify using support vector classifier\n",
    "from sklearn import svm\n",
    "svm = svm.SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
    "\n",
    "# perform classification and prediction on samples in x_test\n",
    "y_pred_svm = svm.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Md54pFHLyd2",
    "outputId": "132e0863-7bea-4670-f038-b35e7eb1aeee"
   },
   "outputs": [],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8R7UD8HFMXaO",
    "outputId": "99780aa0-11a4-4b38-e65a-e80a8e8d3a7f"
   },
   "outputs": [],
   "source": [
    "print(y_pred_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TP5cfPNGOehe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MiniProject1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
